{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert xml to yolo without resizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "def get_image_size(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        return img.size  # returns (width, height)\n",
    "\n",
    "def convert_xml_to_yolo(xml_file, classes, output_dir, original_image_size):\n",
    "    try:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        image_width = original_image_size[0]\n",
    "        image_height = original_image_size[1]\n",
    "        \n",
    "        yolo_annotations = []\n",
    "        \n",
    "        for obj in root.findall('object'):\n",
    "            class_name = obj.find('name').text\n",
    "            if class_name not in classes:\n",
    "                continue\n",
    "            \n",
    "            class_id = classes.index(class_name)\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = float(bndbox.find('xmin').text)\n",
    "            ymin = float(bndbox.find('ymin').text)\n",
    "            xmax = float(bndbox.find('xmax').text)\n",
    "            ymax = float(bndbox.find('ymax').text)\n",
    "            \n",
    "            # Normalize coordinates\n",
    "            x_center = (xmin + xmax) / 2 / image_width\n",
    "            y_center = (ymin + ymax) / 2 / image_height\n",
    "            width = (xmax - xmin) / image_width\n",
    "            height = (ymax - ymin) / image_height\n",
    "            \n",
    "            yolo_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "        \n",
    "        # Write to YOLO annotation file with the same name as the XML file but with a .txt extension\n",
    "        output_file = os.path.join(output_dir, os.path.splitext(os.path.basename(xml_file))[0] + '.txt')\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(\"\\n\".join(yolo_annotations))\n",
    "        \n",
    "        # print(f\"Processed: {xml_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {xml_file}: {e}\")\n",
    "\n",
    "def process_file(args):\n",
    "    xml_file, image_dir, classes, output_dir = args\n",
    "    try:\n",
    "        image_file = os.path.splitext(os.path.basename(xml_file))[0] + '.jpg'\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image file missing: {image_path}\")\n",
    "            return\n",
    "        \n",
    "        original_image_size = get_image_size(image_path)\n",
    "        \n",
    "        # Convert XML annotations to YOLO format\n",
    "        convert_xml_to_yolo(xml_file, classes, output_dir, original_image_size)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {xml_file}: {e}\")\n",
    "\n",
    "def convert_dataset(xml_dir, image_dir, classes, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    xml_files = [os.path.join(xml_dir, f) for f in os.listdir(xml_dir) if f.endswith('.xml')]\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=60) as executor:  # Use 32 cores\n",
    "        futures = [executor.submit(process_file, (xml_file, image_dir, classes, output_dir)) for xml_file in xml_files]\n",
    "        for future in as_completed(futures):\n",
    "            pass  # This will ensure we wait for all tasks to complete\n",
    "\n",
    "# Define the classes\n",
    "classes = [\"gun\"]\n",
    "\n",
    "# Directories\n",
    "xml_dir = '/mnt/storage/kilsar_jainil/Train/Annotations'\n",
    "image_dir = '/mnt/storage/kilsar_jainil/Train/images'\n",
    "output_dir = '/mnt/storage/kilsar_jainil/Train/labels_new'\n",
    "\n",
    "convert_dataset(xml_dir, image_dir, classes, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process blur-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from glob import glob\n",
    "import multiprocessing\n",
    "\n",
    "def is_blurry(image, threshold=100):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    return laplacian_var < threshold\n",
    "\n",
    "def detect_faces(image):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    return faces\n",
    "\n",
    "def check_face_blurriness(image, face_threshold=50):\n",
    "    faces = detect_faces(image)\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_region = image[y:y+h, x:x+w]\n",
    "        if is_blurry(face_region, threshold=face_threshold):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def save_image_and_txt(image_path, output_folder_images, output_folder_labels, labels_folder):\n",
    "    image_name = os.path.basename(image_path)\n",
    "    save_path_image = os.path.join(output_folder_images, image_name)\n",
    "    cv2.imwrite(save_path_image, cv2.imread(image_path))\n",
    "    \n",
    "    txt_name = os.path.splitext(image_name)[0] + \".txt\"\n",
    "    txt_path = os.path.join(labels_folder, txt_name)\n",
    "    if os.path.exists(txt_path):\n",
    "        save_path_txt = os.path.join(output_folder_labels, txt_name)\n",
    "        shutil.copyfile(txt_path, save_path_txt)\n",
    "\n",
    "def process_image(image_path, output_folder_images, output_folder_labels, labels_folder, global_threshold=100, face_threshold=50):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return None, None\n",
    "\n",
    "    if is_blurry(image, threshold=global_threshold):\n",
    "        if not check_face_blurriness(image, face_threshold=face_threshold):\n",
    "            save_image_and_txt(image_path, output_folder_images, output_folder_labels, labels_folder)\n",
    "            return image_path, None\n",
    "        else:\n",
    "            return None, image_path\n",
    "    else:\n",
    "        save_image_and_txt(image_path, output_folder_images, output_folder_labels, labels_folder)\n",
    "        return image_path, None\n",
    "\n",
    "def filter_and_save_images(image_paths, output_folder_images, output_folder_labels, labels_folder, global_threshold=100, face_threshold=50, num_cores=None):\n",
    "    if not os.path.exists(output_folder_images):\n",
    "        os.makedirs(output_folder_images)\n",
    "    if not os.path.exists(output_folder_labels):\n",
    "        os.makedirs(output_folder_labels)\n",
    "\n",
    "    good_images = []\n",
    "    blurry_images = []\n",
    "\n",
    "    if num_cores is None:\n",
    "        num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "        futures = [executor.submit(process_image, image_path, output_folder_images, output_folder_labels, labels_folder, global_threshold, face_threshold) for image_path in image_paths]\n",
    "        for future in as_completed(futures):\n",
    "            good_image, blurry_image = future.result()\n",
    "            if good_image:\n",
    "                good_images.append(good_image)\n",
    "            if blurry_image:\n",
    "                blurry_images.append(blurry_image)\n",
    "\n",
    "    return good_images, blurry_images\n",
    "\n",
    "def gather_image_paths(images_folder):\n",
    "    image_extensions = ['jpg', 'jpeg', 'png', 'bmp']\n",
    "    image_paths = []\n",
    "    for ext in image_extensions:\n",
    "        image_paths.extend(glob(os.path.join(images_folder, f'*.{ext}')))\n",
    "    return image_paths\n",
    "\n",
    "# Example usage\n",
    "images_folders = [\"/home/research/kilasar_sentinal_wepon_detection/data/0/train/images\",\"/home/research/kilasar_sentinal_wepon_detection/data/1/train/images\",\"/home/research/kilasar_sentinal_wepon_detection/data/2/train/images\" , \"/home/research/kilasar_sentinal_wepon_detection/data/n/train/images\",\n",
    "                  \"/home/research/kilasar_sentinal_wepon_detection/data/0/val/images\",\"/home/research/kilasar_sentinal_wepon_detection/data/1/val/images\",\"/home/research/kilasar_sentinal_wepon_detection/data/2/val/images\" , \"/home/research/kilasar_sentinal_wepon_detection/data/n/val/images\"]\n",
    "\n",
    "labels_folders = [\"/home/research/kilasar_sentinal_wepon_detection/data/0/train/labels\" , \"/home/research/kilasar_sentinal_wepon_detection/data/1/train/labels\" , \"/home/research/kilasar_sentinal_wepon_detection/data/2/train/labels\" , \"/home/research/kilasar_sentinal_wepon_detection/data/n/train/labels\",\n",
    "                  \"/home/research/kilasar_sentinal_wepon_detection/data/0/val/labels\" , \"/home/research/kilasar_sentinal_wepon_detection/data/1/val/labels\" , \"/home/research/kilasar_sentinal_wepon_detection/data/2/val/labels\" , \"/home/research/kilasar_sentinal_wepon_detection/data/n/val/labels\"]\n",
    "\n",
    "output_folder_images = [\"/mnt/storage/kilsar-sentinal-data/0/train/images\" , \"/mnt/storage/kilsar-sentinal-data/1/train/images\" , \"/mnt/storage/kilsar-sentinal-data/2/train/images\" , \"/mnt/storage/kilsar-sentinal-data/n/train/images\",\n",
    "                        \"/mnt/storage/kilsar-sentinal-data/0/val/images\" , \"/mnt/storage/kilsar-sentinal-data/1/val/images\" , \"/mnt/storage/kilsar-sentinal-data/2/val/images\" , \"/mnt/storage/kilsar-sentinal-data/n/val/images\"]\n",
    "\n",
    "output_folder_labels = [\"/mnt/storage/kilsar-sentinal-data/0/train/labels\" , \"/mnt/storage/kilsar-sentinal-data/1/train/labels\" , \"/mnt/storage/kilsar-sentinal-data/2/train/labels\" , \"/mnt/storage/kilsar-sentinal-data/n/train/labels\",\n",
    "                        \"/mnt/storage/kilsar-sentinal-data/0/val/labels\" , \"/mnt/storage/kilsar-sentinal-data/1/val/labels\" , \"/mnt/storage/kilsar-sentinal-data/2/val/labels\" , \"/mnt/storage/kilsar-sentinal-data/n/val/labels\"]\n",
    "\n",
    "\n",
    "for i in range(len(images_folders)):\n",
    "    image_paths = gather_image_paths(images_folders[i])\n",
    "    good_images, blurry_images = filter_and_save_images(image_paths, output_folder_images[i], output_folder_labels[i], labels_folders[i], num_cores=60)\n",
    "\n",
    "    print(f\"Good Images for {images_folders[i]} {len(good_images)}\")\n",
    "    print(f\"Blurry Images for {images_folders[i]} {len(blurry_images)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change textfiles classes from from new to old anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_class_label_in_file(filepath, old_class=0, new_class=1):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with open(filepath, 'w') as file:\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if parts[0] == str(old_class):\n",
    "                parts[0] = str(new_class)\n",
    "            file.write(\" \".join(parts) + \"\\n\")\n",
    "\n",
    "def change_class_labels_in_directory(directory, old_class=2, new_class=1, num_workers=None):\n",
    "    txt_files = [os.path.join(directory, filename) for filename in os.listdir(directory) if filename.endswith(\".txt\")]\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [executor.submit(change_class_label_in_file, filepath, old_class, new_class) for filepath in txt_files]\n",
    "        for future in futures:\n",
    "            future.result()  # Ensure any exceptions are raised\n",
    "\n",
    "# Usage\n",
    "directories = ['/home/research/kilasar_sentinal_wepon_detection/data/0/test/labels','/home/research/kilasar_sentinal_wepon_detection/data/0/train/labels','/home/research/kilasar_sentinal_wepon_detection/data/0/val/labels']\n",
    "for directory in directories:\n",
    "    change_class_labels_in_directory(directory, old_class=0, new_class=1, num_workers=36)\n",
    "    print(directory , 'folder compelted ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRONG : split data from images and labels 0.8 0.1 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data copied successfully into train, valid, and test sets with separate folders for images and labels using ProcessPoolExecutor with 32 cores.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Directories\n",
    "images_dir = '/mnt/storage/kilsar_jainil/train/Train/JPEGImages/'\n",
    "labels_dir = '/mnt/storage/kilsar_jainil/train/Train/labels'\n",
    "# Output directories\n",
    "output_base_dir = '/home/research/kilasar_sentinal_wepon_detection/suryansh/outsiside_data/dataset-2'\n",
    "train_images_dir = os.path.join(output_base_dir, 'train/images')\n",
    "train_labels_dir = os.path.join(output_base_dir, 'train/labels')\n",
    "valid_images_dir = os.path.join(output_base_dir, 'valid/images')\n",
    "valid_labels_dir = os.path.join(output_base_dir, 'valid/labels')\n",
    "test_images_dir = os.path.join(output_base_dir, 'test/images')\n",
    "test_labels_dir = os.path.join(output_base_dir, 'test/labels')\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(train_labels_dir, exist_ok=True)\n",
    "os.makedirs(valid_images_dir, exist_ok=True)\n",
    "os.makedirs(valid_labels_dir, exist_ok=True)\n",
    "os.makedirs(test_images_dir, exist_ok=True)\n",
    "os.makedirs(test_labels_dir, exist_ok=True)\n",
    "\n",
    "# List all files in images_dir and labels_dir\n",
    "images_files = os.listdir(images_dir)\n",
    "labels_files = os.listdir(labels_dir)\n",
    "\n",
    "\n",
    "\n",
    "# # Shuffle the lists\n",
    "# random.shuffle(images_files)\n",
    "# random.shuffle(labels_files)\n",
    "\n",
    "\n",
    "# Calculate split sizes\n",
    "total_files = len(images_files)\n",
    "train_split = int(total_files * 0.8)\n",
    "valid_split = int(total_files * 0.1)\n",
    "\n",
    "# Split the data\n",
    "train_images = images_files[:train_split]\n",
    "valid_images = images_files[train_split:train_split + valid_split]\n",
    "test_images = images_files[train_split + valid_split:]\n",
    "\n",
    "train_labels = labels_files[:train_split]\n",
    "valid_labels = labels_files[train_split:train_split + valid_split]\n",
    "test_labels = labels_files[train_split + valid_split:]\n",
    "\n",
    "# Function to copy files\n",
    "def copy_files(files, source_dir, dest_dir):\n",
    "    for file in files:\n",
    "        shutil.copy(os.path.join(source_dir, file), dest_dir)\n",
    "\n",
    "# Use ProcessPoolExecutor with 32 cores\n",
    "n_workers = 55\n",
    "with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "    # Copy train images and labels\n",
    "    executor.submit(copy_files, train_images, images_dir, train_images_dir)\n",
    "    executor.submit(copy_files, train_labels, labels_dir, train_labels_dir)\n",
    "    \n",
    "    # Copy validation images and labels\n",
    "    executor.submit(copy_files, valid_images, images_dir, valid_images_dir)\n",
    "    executor.submit(copy_files, valid_labels, labels_dir, valid_labels_dir)\n",
    "    \n",
    "    # Copy test images and labels\n",
    "    executor.submit(copy_files, test_images, images_dir, test_images_dir)\n",
    "    executor.submit(copy_files, test_labels, labels_dir, test_labels_dir)\n",
    "\n",
    "print(\"Data copied successfully into train, valid, and test sets with separate folders for images and labels using ProcessPoolExecutor with 32 cores.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRECT : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Directories\n",
    "images_dir = '/mnt/storage/kilsar_jainil/train/Train/JPEGImages/'\n",
    "labels_dir = '/mnt/storage/kilsar_jainil/train/Train/labels'\n",
    "# Output directories\n",
    "output_base_dir = '/home/research/kilasar_sentinal_wepon_detection/suryansh/outsiside_data/dataset-3'\n",
    "train_images_dir = os.path.join(output_base_dir, 'train/images')\n",
    "train_labels_dir = os.path.join(output_base_dir, 'train/labels')\n",
    "valid_images_dir = os.path.join(output_base_dir, 'valid/images')\n",
    "valid_labels_dir = os.path.join(output_base_dir, 'valid/labels')\n",
    "test_images_dir = os.path.join(output_base_dir, 'test/images')\n",
    "test_labels_dir = os.path.join(output_base_dir, 'test/labels')\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(train_labels_dir, exist_ok=True)\n",
    "os.makedirs(valid_images_dir, exist_ok=True)\n",
    "os.makedirs(valid_labels_dir, exist_ok=True)\n",
    "os.makedirs(test_images_dir, exist_ok=True)\n",
    "os.makedirs(test_labels_dir, exist_ok=True)\n",
    "\n",
    "# List all image files\n",
    "image_files = os.listdir(images_dir)\n",
    "\n",
    "# Create image-label pairs\n",
    "image_label_pairs = [(img, img.replace('.jpg', '.txt')) for img in image_files]\n",
    "\n",
    "# Filter out pairs where either the image or the label file doesn't exist\n",
    "image_label_pairs = [(img, lbl) for img, lbl in image_label_pairs if os.path.exists(os.path.join(labels_dir, lbl))]\n",
    "\n",
    "# Shuffle the list\n",
    "random.shuffle(image_label_pairs)\n",
    "\n",
    "# Calculate split sizes\n",
    "total_files = len(image_label_pairs)\n",
    "train_split = int(total_files * 0.8)\n",
    "valid_split = int(total_files * 0.1)\n",
    "\n",
    "# Split the data\n",
    "train_pairs = image_label_pairs[:train_split]\n",
    "valid_pairs = image_label_pairs[train_split:train_split + valid_split]\n",
    "test_pairs = image_label_pairs[train_split + valid_split:]\n",
    "\n",
    "# Function to copy files\n",
    "def copy_files(pairs, images_dir, labels_dir, dest_images_dir, dest_labels_dir):\n",
    "    for img_file, lbl_file in pairs:\n",
    "        shutil.copy(os.path.join(images_dir, img_file), dest_images_dir)\n",
    "        shutil.copy(os.path.join(labels_dir, lbl_file), dest_labels_dir)\n",
    "\n",
    "# Use ProcessPoolExecutor with 32 cores\n",
    "n_workers = 32\n",
    "with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "    # Copy train images and labels\n",
    "    executor.submit(copy_files, train_pairs, images_dir, labels_dir, train_images_dir, train_labels_dir)\n",
    "    \n",
    "    # Copy validation images and labels\n",
    "    executor.submit(copy_files, valid_pairs, images_dir, labels_dir, valid_images_dir, valid_labels_dir)\n",
    "    \n",
    "    # Copy test images and labels\n",
    "    executor.submit(copy_files, test_pairs, images_dir, labels_dir, test_images_dir, test_labels_dir)\n",
    "\n",
    "print(\"Data copied successfully into train, valid, and test sets with separate folders for images and labels using ProcessPoolExecutor with 32 cores.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating dataset form drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def create_yolo_annotation():\n",
    "    # YOLO annotation: class (0), x_center, y_center, width, height\n",
    "    # Since the bounding box covers the entire image:\n",
    "    # x_center, y_center = 0.5 (center of the image in normalized coordinates)\n",
    "    # width, height = 1.0 (whole image in normalized coordinates)\n",
    "    return \"0 0.5 0.5 1.0 1.0\\n\"\n",
    "\n",
    "def process_image(filename, image_folder, output_folder, yolo_annotation):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Add other image formats if needed\n",
    "        # Create the corresponding .txt file\n",
    "        txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        txt_path = os.path.join(output_folder, txt_filename)\n",
    "        \n",
    "        # Write the YOLO annotation to the .txt file\n",
    "        with open(txt_path, \"w\") as txt_file:\n",
    "            txt_file.write(yolo_annotation)\n",
    "\n",
    "def create_yolo_files(image_folder, output_folder, num_workers=32):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    yolo_annotation = create_yolo_annotation()\n",
    "    \n",
    "    # Get list of files to process\n",
    "    filenames = [f for f in os.listdir(image_folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "    \n",
    "    # Use ProcessPoolExecutor to process images in parallel\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [executor.submit(process_image, filename, image_folder, output_folder, yolo_annotation) for filename in filenames]\n",
    "        \n",
    "        # Ensure all futures are completed\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "\n",
    "# Path to the folder containing the images\n",
    "image_folder = '/mnt/storage/kilsar_jainil/drive-download-20240626T221301Z-001/classifier/gun/train/'\n",
    "\n",
    "# Path to the folder where YOLO files will be saved\n",
    "output_folder = '/mnt/storage/kilsar_jainil/drive-download-20240626T221301Z-001/classifier/gun/labels/train/'\n",
    "\n",
    "# Create YOLO formatted text files using 32 cores\n",
    "create_yolo_files(image_folder, output_folder, num_workers=60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
