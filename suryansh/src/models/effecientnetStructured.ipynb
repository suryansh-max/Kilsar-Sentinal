{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/home/research/Kilsar_Sentinal/EfficientNet data/splitted_data/train'\n",
    "val_dir = '/home/research/Kilsar_Sentinal/EfficientNet data/splitted_data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Hyperparameters\n",
    "input_shape = (300, 300, 3)         \n",
    "num_classes = 2                       \n",
    "dropout_rate = 0.4                    \n",
    "\n",
    "# Model Architecture Hyperparameters\n",
    "dense_units_1 = 256                 \n",
    "dense_units_2 = 128                 \n",
    "\n",
    "# Data Augmentation Hyperparameters\n",
    "rescale_value = 1./255             \n",
    "rotation_range = 20                 \n",
    "width_shift_range = 0.2\n",
    "height_shift_range = 0.2              \n",
    "shear_range = 0.2                  \n",
    "zoom_range = 0.2                     \n",
    "horizontal_flip = True            \n",
    "fill_mode = 'nearest'              \n",
    "\n",
    "# Training Hyperparameters\n",
    "batch_size = 15                      \n",
    "epochs = 10                               \n",
    "\n",
    "# Callbacks Hyperparameters\n",
    "reduce_lr_factor = 0.2             \n",
    "reduce_lr_patience = 3            \n",
    "min_lr = 1e-6                     \n",
    "early_stopping_patience = 5      \n",
    "\n",
    "# optimizerAdam = 'adam'\n",
    "optimizerAdam = AdamW(\n",
    "    learning_rate=0.005,\n",
    "    weight_decay=0.004,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    clipnorm=None,\n",
    "    clipvalue=None,\n",
    "    global_clipnorm=None,\n",
    "    use_ema=False,\n",
    "    ema_momentum=0.99,\n",
    "    ema_overwrite_frequency=None,\n",
    "    loss_scale_factor=None,\n",
    "    gradient_accumulation_steps=None,\n",
    "    name='adamw',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,783,535</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb3 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │    \u001b[38;5;34m10,783,535\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m393,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,210,161</span> (42.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,210,161\u001b[0m (42.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,122,858</span> (42.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,122,858\u001b[0m (42.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">87,303</span> (341.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m87,303\u001b[0m (341.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = EfficientNetB3(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=input_shape,\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Dense(dense_units_1, activation='relu'),\n",
    "    layers.Dense(dense_units_2, activation='relu'),\n",
    "    layers.Dropout(dropout_rate),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizerAdam,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=rescale_value,\n",
    "    rotation_range=rotation_range,\n",
    "    width_shift_range=width_shift_range,\n",
    "    height_shift_range=height_shift_range,\n",
    "    shear_range=shear_range,\n",
    "    zoom_range=zoom_range,\n",
    "    horizontal_flip=horizontal_flip,\n",
    "    fill_mode=fill_mode\n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=rescale_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7996 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(input_shape[0], input_shape[1]), \n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(input_shape[0], input_shape[1]), \n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_lr_factor, patience=reduce_lr_patience, min_lr=min_lr)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True)\n",
    "callbacks = [reduce_lr, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 20:41:38.869468: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at xla_ops.cc:577 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv.569 = (f32[15,144,151,151]{3,2,1,0}, u8[0]{0}) custom-call(f32[15,144,153,153]{3,2,1,0} %pad.27, f32[144,1,3,3]{3,2,1,0} %transpose.1718), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=144, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"DepthwiseConv2dNativeBackpropInput\" op_name=\"gradient_tape/sequential_8_1/efficientnetb3_1/block2a_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropInput\" source_file=\"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 219030976 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib64/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib64/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib64/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_1467527/407577562.py\", line 1, in <module>\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv.569 = (f32[15,144,151,151]{3,2,1,0}, u8[0]{0}) custom-call(f32[15,144,153,153]{3,2,1,0} %pad.27, f32[144,1,3,3]{3,2,1,0} %transpose.1718), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=144, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"DepthwiseConv2dNativeBackpropInput\" op_name=\"gradient_tape/sequential_8_1/efficientnetb3_1/block2a_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropInput\" source_file=\"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 219030976 bytes.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_iterator_972100]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF_CPP_MIN_VLOG_LEVEL\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib64/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib64/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib64/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_1467527/407577562.py\", line 1, in <module>\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv.569 = (f32[15,144,151,151]{3,2,1,0}, u8[0]{0}) custom-call(f32[15,144,153,153]{3,2,1,0} %pad.27, f32[144,1,3,3]{3,2,1,0} %transpose.1718), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=144, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"DepthwiseConv2dNativeBackpropInput\" op_name=\"gradient_tape/sequential_8_1/efficientnetb3_1/block2a_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropInput\" source_file=\"/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 219030976 bytes.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_iterator_972100]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appy Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Define the function to build the model\n",
    "def create_model(dense_units_1=256, dense_units_2=128, dropout_rate=0.2, learning_rate=0.001, input_shape=(300, 300, 3), num_classes=2):\n",
    "    base_model = EfficientNetB3(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n",
    "    \n",
    "    # Create a Sequential model and add layers\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Dense(dense_units_1, activation='relu'),\n",
    "        layers.Dense(dense_units_2, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Wrap the model with KerasClassifier\n",
    "model = KerasClassifier(model=create_model, verbose=1)\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'dense_units_1': [128, 256, 512],\n",
    "    'dense_units_2': [64, 128, 256],\n",
    "    'dropout_rate': [0.2, 0.3, 0.4],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [10, 20]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "\n",
    "# Prepare your training data\n",
    "train_dir = '/home/research/Kilsar_Sentinal/EfficientNet data/splitted_data/train'\n",
    "val_dir = '/home/research/Kilsar_Sentinal/EfficientNet data/splitted_data/val'\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Fit the GridSearch\n",
    "try:\n",
    "    grid_result = grid.fit(train_generator, verbose=1)\n",
    "except Exception as e:\n",
    "    print(f\"Error during GridSearch fitting: {e}\")\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# enabling gpu\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU memory growth set successfully.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error setting memory growth: {e}\")\n",
    "\n",
    "\n",
    "# Define a function for model building that integrates with Keras Tuner\n",
    "def build_model(hp):\n",
    "    base_model = EfficientNetB3(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(300, 300, 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    \n",
    "    # Create the model\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Dense(hp.Int('dense_units_1', min_value=128, max_value=512, step=128), activation='relu'),\n",
    "        layers.Dense(hp.Int('dense_units_2', min_value=64, max_value=256, step=64), activation='relu'),\n",
    "        layers.Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.4, step=0.1)),\n",
    "        layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create a tuner instance\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='tuner_dir',\n",
    "    project_name='hyperparam_tuning'\n",
    ")\n",
    "\n",
    "# Prepare training data\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "tuner.search(train_generator, epochs=10, validation_data=train_generator)\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters: {best_hps.values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
