{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effecient Nets\n",
    "use EfficientNet models for real-time applications using TensorFlow Lite. TensorFlow Lite is designed to optimize models for deployment on edge devices, providing smaller model sizes and faster inference times. EfficientNet models, especially the smaller variants like B0-B3, are well-suited for deployment using TensorFlow Lite on devices with limited computational resources, such as smartphones, Raspberry Pi, or IoT devices.\n",
    "\n",
    "Steps to Use EfficientNet with TensorFlow Lite\n",
    "Convert EfficientNet Model to TensorFlow Lite Format:\n",
    "\n",
    "You need to convert the TensorFlow/Keras EfficientNet model to a .tflite format.\n",
    "Use TensorFlow’s tf.lite.TFLiteConverter to convert the trained model.\n",
    "Quantization:\n",
    "\n",
    "Apply quantization techniques (e.g., post-training quantization) to further reduce the model size and improve inference speed.\n",
    "Supported quantization types include float16, int8, and dynamic range.\n",
    "Deploy on Edge Device:\n",
    "\n",
    "Deploy the .tflite model on your target device, such as a Raspberry Pi or Android smartphone.\n",
    "Use TensorFlow Lite’s interpreter to load and run inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow  \n",
    "import tflite \n",
    "print(tensorflow.__version__ , tflite.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 15:35:43.148404: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-16 15:35:43.159228: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-16 15:35:43.170458: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-16 15:35:43.173865: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-16 15:35:43.183816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 15:35:43.807954: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# sample code to generate data generators\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 15:35:52.175121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 419 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 0000:4a:00.0, compute capability: 8.0\n",
      "2024-10-16 15:35:52.177170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22170 MB memory:  -> device: 1, name: NVIDIA A30, pci bus id: 0000:61:00.0, compute capability: 8.0\n",
      "2024-10-16 15:35:52.179118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22170 MB memory:  -> device: 2, name: NVIDIA A30, pci bus id: 0000:ca:00.0, compute capability: 8.0\n",
      "2024-10-16 15:35:52.181307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22170 MB memory:  -> device: 3, name: NVIDIA A30, pci bus id: 0000:e1:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# General Hyperparameters\n",
    "input_shape = (300, 300, 3)         \n",
    "num_classes = 2                       \n",
    "dropout_rate = 0.4                    \n",
    "\n",
    "# Model Architecture Hyperparameters\n",
    "dense_units_1 = 256                 \n",
    "dense_units_2 = 128                 \n",
    "\n",
    "# Data Augmentation Hyperparameters\n",
    "rescale_value = 1./255             \n",
    "rotation_range = 20                 \n",
    "width_shift_range = 0.2\n",
    "height_shift_range = 0.2              \n",
    "shear_range = 0.2                  \n",
    "zoom_range = 0.2                     \n",
    "horizontal_flip = True            \n",
    "fill_mode = 'nearest'              \n",
    "\n",
    "# Training Hyperparameters\n",
    "batch_size = 15                      \n",
    "epochs = 10                               \n",
    "\n",
    "# Callbacks Hyperparameters\n",
    "reduce_lr_factor = 0.2             \n",
    "reduce_lr_patience = 3            \n",
    "min_lr = 1e-6                     \n",
    "early_stopping_patience = 5      \n",
    "\n",
    "# # optimizerAdam = 'adam'\n",
    "# optimizerAdam = AdamW(\n",
    "#     learning_rate=0.001,\n",
    "#     weight_decay=0.004,\n",
    "#     beta_1=0.9,\n",
    "#     beta_2=0.999,\n",
    "#     epsilon=1e-07,\n",
    "#     amsgrad=False,\n",
    "#     clipnorm=None,\n",
    "#     clipvalue=None,\n",
    "#     global_clipnorm=None,\n",
    "#     use_ema=False,\n",
    "#     ema_momentum=0.99,\n",
    "#     ema_overwrite_frequency=None,\n",
    "#     loss_scale_factor=None,\n",
    "#     gradient_accumulation_steps=None,\n",
    "#     name='adamw',\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch > 5:\n",
    "        lr = lr * 0.1  # Reduce learning rate after 5 epochs\n",
    "    return lr\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,783,535</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">786,944</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb3 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │    \u001b[38;5;34m10,783,535\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m786,944\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,734,961</span> (44.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,734,961\u001b[0m (44.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,647,658</span> (44.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,647,658\u001b[0m (44.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">87,303</span> (341.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m87,303\u001b[0m (341.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = (300, 300, 3)\n",
    "\n",
    "optimizerAdam = AdamW(\n",
    "    learning_rate=0.005,\n",
    "    weight_decay=0.004,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    clipnorm=None,\n",
    "    clipvalue=None,\n",
    "    global_clipnorm=None,\n",
    "    use_ema=False,\n",
    "    ema_momentum=0.99,\n",
    "    ema_overwrite_frequency=None,\n",
    "    loss_scale_factor=None,\n",
    "    gradient_accumulation_steps=None,\n",
    "    name='adamw',\n",
    ")\n",
    "\n",
    "base_model = EfficientNetB3(\n",
    "    include_top=False,            \n",
    "    weights='imagenet',        \n",
    "    input_shape=input_shape,     \n",
    "    pooling='avg'                \n",
    ")\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,   \n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.2),                              \n",
    "    layers.Dense(256, activation='relu'),          \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.4),                         \n",
    "    layers.Dense(2, activation='softmax')           \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizerAdam,\n",
    "    loss='categorical_crossentropy',           \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras', monitor='val_loss', save_best_only=True, save_weights_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7996 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/home/research/Kilsar_Sentinal/EfficientNet data/splitted_data/train',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    '/home/research/Kilsar_Sentinal/EfficientNet data/splitted_data/val',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/Kilsar_Sentinal/.venv/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728520856.854215 1466927 service.cc:146] XLA service 0x7f648c002ee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728520856.854246 1466927 service.cc:154]   StreamExecutor device (0): NVIDIA A30, Compute Capability 8.0\n",
      "I0000 00:00:1728520856.854249 1466927 service.cc:154]   StreamExecutor device (1): NVIDIA A30, Compute Capability 8.0\n",
      "I0000 00:00:1728520856.854250 1466927 service.cc:154]   StreamExecutor device (2): NVIDIA A30, Compute Capability 8.0\n",
      "I0000 00:00:1728520856.854252 1466927 service.cc:154]   StreamExecutor device (3): NVIDIA A30, Compute Capability 8.0\n",
      "2024-10-09 19:40:57.793202: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-09 19:41:01.248394: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8902\n",
      "2024-10-09 19:41:05.771292: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38143', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-10-09 19:41:05.953851: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38143', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-09 19:41:06.004398: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38143', 168 bytes spill stores, 168 bytes spill loads\n",
      "\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1728520881.327703 1466927 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1728520881.483656 1466927 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1728520882.050292 1466927 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1728520882.207200 1466927 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2024-10-09 19:41:44.471022: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_80', 8 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1728520904.774213 1466927 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 45/249\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 261ms/step - accuracy: 0.7489 - loss: 0.7458"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 19:42:04.299355: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38409', 36 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2024-10-09 19:42:04.357272: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38143', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2024-10-09 19:42:04.373895: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38407', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-10-09 19:42:04.390944: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38143', 196 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "E0000 00:00:1728520938.364898 1466930 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1728520938.520061 1466930 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1728520939.071397 1466930 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1728520939.228341 1466930 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 480ms/step - accuracy: 0.7890 - loss: 0.5739 - val_accuracy: 0.8085 - val_loss: 0.6623 - learning_rate: 0.0050\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/249\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 153ms/step - accuracy: 0.8438 - loss: 0.4583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 19:43:44.331860: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-10-09 19:43:44.332479: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "/usr/lib64/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.8438 - loss: 0.4583 - val_accuracy: 0.9375 - val_loss: 0.6744 - learning_rate: 0.0050\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 19:43:51.546725: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 273ms/step - accuracy: 0.8102 - loss: 0.4390 - val_accuracy: 0.8100 - val_loss: 2.2421 - learning_rate: 0.0050\n",
      "Epoch 4/10\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166us/step - accuracy: 0.8438 - loss: 0.4391 - val_accuracy: 0.7500 - val_loss: 3.0821 - learning_rate: 1.0000e-03\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 19:44:59.963639: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 274ms/step - accuracy: 0.8213 - loss: 0.3973 - val_accuracy: 0.8100 - val_loss: 0.7882 - learning_rate: 1.0000e-03\n",
      "Epoch 6/10\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162us/step - accuracy: 0.8438 - loss: 0.2463 - val_accuracy: 0.7500 - val_loss: 1.0336 - learning_rate: 1.0000e-03\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    callbacks=[reduce_lr, early_stopping, checkpoint, lr_callback] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To unfreez layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 275ms/step - accuracy: 0.8637 - loss: 0.3334 - val_accuracy: 0.8105 - val_loss: 0.8046 - learning_rate: 1.0000e-03\n",
      "Epoch 2/5\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172us/step - accuracy: 0.8438 - loss: 0.3316 - val_accuracy: 0.7500 - val_loss: 0.8468 - learning_rate: 1.0000e-03\n",
      "Epoch 3/5\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 271ms/step - accuracy: 0.8652 - loss: 0.3239 - val_accuracy: 0.8105 - val_loss: 0.5964 - learning_rate: 1.0000e-03\n",
      "Epoch 4/5\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165us/step - accuracy: 0.9062 - loss: 0.2383 - val_accuracy: 0.6875 - val_loss: 0.8476 - learning_rate: 1.0000e-03\n",
      "Epoch 5/5\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 273ms/step - accuracy: 0.8823 - loss: 0.2917 - val_accuracy: 0.8100 - val_loss: 0.6549 - learning_rate: 1.0000e-03\n",
      "Epoch 1/10\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 394ms/step - accuracy: 0.8585 - loss: 0.3232 - val_accuracy: 0.8760 - val_loss: 0.3168 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/249\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 156ms/step - accuracy: 0.9062 - loss: 0.2842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 20:37:38.624046: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9062 - loss: 0.2842 - val_accuracy: 1.0000 - val_loss: 0.1659 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 274ms/step - accuracy: 0.8660 - loss: 0.3110 - val_accuracy: 0.8458 - val_loss: 0.3673 - learning_rate: 1.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165us/step - accuracy: 0.9062 - loss: 0.2650 - val_accuracy: 0.8750 - val_loss: 0.4229 - learning_rate: 1.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 272ms/step - accuracy: 0.8789 - loss: 0.2945 - val_accuracy: 0.8140 - val_loss: 0.5905 - learning_rate: 1.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166us/step - accuracy: 0.8750 - loss: 0.2435 - val_accuracy: 0.7500 - val_loss: 0.8426 - learning_rate: 2.0000e-06\n",
      "Epoch 7/10\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 273ms/step - accuracy: 0.8756 - loss: 0.3009 - val_accuracy: 0.8967 - val_loss: 0.2659 - learning_rate: 2.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Initial training with frozen base model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    callbacks=[reduce_lr, early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Unfreeze base model and fine-tune with a lower learning rate\n",
    "base_model.trainable = True\n",
    "model.compile(optimizer=AdamW(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    callbacks=[reduce_lr, early_stopping, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    # Build a model with hyperparameters to tune\n",
    "    base_model = EfficientNetB3(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Dense(hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'),\n",
    "        layers.Dense(hp.Int('units2', min_value=32, max_value=256, step=32), activation='relu'),\n",
    "        layers.Dropout(hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)),\n",
    "        layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', [1e-3, 1e-4, 1e-5])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Create a tuner and search for the best hyperparameters\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner',\n",
    "    project_name='efficientnet_tuning'\n",
    ")\n",
    "tuner.search(train_generator, validation_data=val_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "\n",
    "\n",
    "input_shape = (300, 300, 3)\n",
    "\n",
    "base_model = EfficientNetB3(\n",
    "    include_top=False,            \n",
    "    weights='imagenet',        \n",
    "    input_shape=input_shape,     \n",
    "    pooling='avg'                \n",
    ")\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,                                 \n",
    "    layers.Dense(256, activation='relu'),          \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),                         \n",
    "    layers.Dense(2, activation='softmax')           \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',           \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Summary of the custom model\n",
    "model.summary()\n",
    "\n",
    "# Training\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/home/research/Kilsar_Sentinal/EfficientNet data/splitted_data/train',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    '/home/research/Kilsar_Sentinal/EfficientNet data/splitted_data/val',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save converted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/research/Kilsar_Sentinal/suryansh/src/models/tf models/model-2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('efficientnet_b0_saved_model')\n",
    "# Optional: apply optimizations like quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted .tflite model\n",
    "with open('efficientnet_b0.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the EfficientNetB3 model\n",
    "model = tf.keras.applications.EfficientNetB3(\n",
    "    include_top=True,\n",
    "    weights='imagenet',  \n",
    "    input_shape=(300, 300, 3) \n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "\n",
    "# Define input shape based on the dataset (e.g., 300x300 RGB images)\n",
    "input_shape = (300, 300, 3)\n",
    "\n",
    "# Load the EfficientNet-B3 model with custom settings\n",
    "base_model = EfficientNetB3(\n",
    "    include_top=False,            # Remove the default top layer to add custom layers\n",
    "    weights='imagenet',           # Use pre-trained ImageNet weights\n",
    "    input_shape=input_shape,      # Set input shape\n",
    "    pooling='avg'                 # Apply global average pooling\n",
    ")\n",
    "\n",
    "# Freeze the base model layers to retain pre-trained features\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a new model on top of the base model\n",
    "model = models.Sequential([\n",
    "    base_model,                                    # EfficientNetB3 base model\n",
    "    layers.Dense(256, activation='relu'),          # Custom fully connected layer for feature extraction\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),                           # Dropout layer for regularization\n",
    "    layers.Dense(2, activation='softmax')          # Output layer with 2 classes (for 2 gun types)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',               # Use categorical cross-entropy for multi-class classification\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Summary of the custom model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error setting memory growth: Physical devices cannot be modified after being initialized\n",
      "Reloading Tuner from tuner_dir/hyperparam_tuning/tuner0.json\n",
      "Found 7996 images belonging to 2 classes.\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "512               |128               |dense_units_1\n",
      "256               |128               |dense_units_2\n",
      "0.4               |0.2               |dropout_rate\n",
      "0.001             |0.0001            |learning_rate\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 20:43:40.558117: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36329', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-09 20:43:40.712028: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36079', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-10-09 20:43:40.992237: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36079', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-09 20:43:41.089026: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36079', 168 bytes spill stores, 168 bytes spill loads\n",
      "\n",
      "2024-10-09 20:44:03.302548: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_79', 8 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m167/250\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 146ms/step - accuracy: 0.8853 - loss: 0.3005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 20:44:35.845524: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36329', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2024-10-09 20:44:36.130685: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36343', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-10-09 20:44:36.150607: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36345', 36 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2024-10-09 20:44:36.180024: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36079', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2024-10-09 20:44:36.213519: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36079', 196 bytes spill stores, 196 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 351ms/step - accuracy: 0.8944 - loss: 0.2819 - val_accuracy: 0.8098 - val_loss: 0.4993\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.9532 - loss: 0.1419"
     ]
    }
   ],
   "source": [
    "import kerastuner as kt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "train_dir = '/home/research/Kilsar_Sentinal/EfficientNet data/splitted_data/train'\n",
    "\n",
    "# enabling gpu\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU memory growth set successfully.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error setting memory growth: {e}\")\n",
    "\n",
    "\n",
    "# Define a function for model building that integrates with Keras Tuner\n",
    "def build_model(hp):\n",
    "    base_model = EfficientNetB3(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(300, 300, 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    \n",
    "    # Create the model\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Dense(hp.Int('dense_units_1', min_value=128, max_value=512, step=128), activation='relu'),\n",
    "        layers.Dense(hp.Int('dense_units_2', min_value=64, max_value=256, step=64), activation='relu'),\n",
    "        layers.Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.4, step=0.1)),\n",
    "        layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create a tuner instance\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='tuner_dir',\n",
    "    project_name='hyperparam_tuning'\n",
    ")\n",
    "\n",
    "# Prepare training data\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "tuner.search(train_generator, epochs=10, validation_data=train_generator)\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters: {best_hps.values}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
